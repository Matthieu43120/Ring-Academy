import React, { useState, useEffect, useRef } from 'react';
import { Phone, PhoneOff, Volume2, VolumeX } from 'lucide-react';
import { TrainingConfig, SessionResult } from '../pages/Training';
import { generateAIResponseFast, analyzeCall, ConversationContext, generateAndPlaySegmentAudio } from '../services/openai';
import { phoneCallService } from '../services/phoneCallService';

interface PhoneCallSimulatorProps {
  config: TrainingConfig;
  onCallComplete: (result: SessionResult) => void;
}

type CallState = 'dialing' | 'ringing' | 'connected' | 'ended';

function PhoneCallSimulator({ config, onCallComplete }: PhoneCallSimulatorProps) {
  const [callState, setCallState] = useState<CallState>('dialing');
  const [callDuration, setCallDuration] = useState(0);
  const [startTime, setStartTime] = useState<Date | null>(null);
  const [endTime, setEndTime] = useState<Date | null>(null);
  const [isMuted, setIsMuted] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [isAISpeaking, setIsAISpeaking] = useState(false);
  const [aiThinking, setAiThinking] = useState(false);
  const [partialAIText, setPartialAIText] = useState('');
  
  // File d'attente audio pour des r√©ponses fluides
  const audioQueueRef = useRef<string[]>([]);
  const isAudioPlayingRef = useRef(false);
  const aiResponseCompleteRef = useRef(false);
  const shouldEndCallAfterAudioRef = useRef(false);
  
  const [conversationContext, setConversationContext] = useState<ConversationContext>({
    target: config.target,
    difficulty: config.difficulty,
    conversationHistory: []
  });

  // ULTRA-OPTIMISATION: Refs pour √©viter les race conditions
  const callStateRef = useRef<CallState>('dialing');
  const processingResponseRef = useRef(false);
  const callStarted = useRef(false);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  
  // REF CRITIQUE: Historique de conversation en temps r√©el
  const conversationHistoryRef = useRef<Array<{ role: 'user' | 'assistant'; content: string }>>([]);

  // Synchroniser les refs avec les states
  useEffect(() => {
    callStateRef.current = callState;
  }, [callState]);

  useEffect(() => {
    conversationHistoryRef.current = conversationContext.conversationHistory;
  }, [conversationContext.conversationHistory]);

  // Callback pour traiter les phrases audio de mani√®re asynchrone
  const onSentenceReadyForAudio = useCallback((sentence: string) => {
    if (!isMuted) {
      console.log('üéµ Ajout √† la file d\'attente audio:', sentence);
      audioQueueRef.current.push(sentence);
      
      // D√©marrer la lecture si aucun audio n'est en cours
      if (!isAudioPlayingRef.current) {
        processAudioQueue();
      }
    }
  }, [isMuted]);

  // Traiter la file d'attente audio
  const processAudioQueue = useCallback(async () => {
    if (isAudioPlayingRef.current || audioQueueRef.current.length === 0) {
      // Si la file est vide et que la r√©ponse IA est compl√®te, lib√©rer le micro
      if (audioQueueRef.current.length === 0 && aiResponseCompleteRef.current) {
        console.log('üé§ Tous les audios jou√©s, lib√©ration du micro');
        phoneCallService.setAISpeaking(false);
        setIsAISpeaking(false);
        
        // Terminer l'appel si demand√©
        if (shouldEndCallAfterAudioRef.current) {
          setTimeout(() => {
            handleEndCall();
          }, 500);
        }
      }
      return;
    }

    isAudioPlayingRef.current = true;
    const sentence = audioQueueRef.current.shift()!;
    
    try {
      console.log('üîä Lecture audio:', sentence);
      await generateAndPlaySegmentAudio(sentence);
    } catch (error) {
      console.error('‚ùå Erreur lecture audio:', error);
    } finally {
      isAudioPlayingRef.current = false;
      // Continuer avec le prochain segment
      processAudioQueue();
    }
  }, []);

  // Timer de l'appel
  useEffect(() => {
    let interval: NodeJS.Timeout;
    if (callState === 'connected' && startTime) {
      interval = setInterval(() => {
        setCallDuration(Math.floor((Date.now() - startTime.getTime()) / 1000));
      }, 1000);
    }
    return () => clearInterval(interval);
  }, [callState, startTime]);

  // D√©marrer l'appel
  useEffect(() => {
    if (!callStarted.current) {
      callStarted.current = true;
      initiateCall();
    }
  }, []);

  const initiateCall = async () => {
    try {
      setCallState('ringing');
      callStateRef.current = 'ringing';
      
      // Jouer la sonnerie
      await phoneCallService.playRingtone();
      
      // L'IA d√©croche - UTILISER LES REFS pour √©viter les race conditions
      setCallState('connected');
      callStateRef.current = 'connected'; // CRITIQUE: Mettre √† jour la ref imm√©diatement
      setStartTime(new Date());
      
      // Premi√®re r√©ponse de l'IA (obligatoire "All√¥ ?")
      await handleFirstAIResponse();
      
      // ULTRA-OPTIMISATION: Activation micro imm√©diate
      setTimeout(async () => {
        if (phoneCallService.isSupported()) {
          await phoneCallService.startContinuousRecording(handleUserSpeech);
        } else {
          setError('Microphone non support√©. Utilisez un navigateur compatible.');
        }
      }, 25); // ULTRA-R√âDUCTION: 50ms ‚Üí 25ms
      
    } catch (error) {
      setError('Impossible de d√©marrer l\'appel. V√©rifiez vos permissions microphone.');
    }
  };

  const handleFirstAIResponse = async () => {
    setError(null);
    setIsAISpeaking(true);
    phoneCallService.setAISpeaking(true);
    setAiThinking(true);
    
    // R√©initialiser la file d'attente audio
    audioQueueRef.current = [];
    isAudioPlayingRef.current = false;
    aiResponseCompleteRef.current = false;
    shouldEndCallAfterAudioRef.current = false;

    try {
      // Pr√©parer le contexte pour la premi√®re r√©ponse
      const context: ConversationContext = {
        target: config.target,
        difficulty: config.difficulty,
        conversationHistory: []
      };
      
      // G√©n√©rer la r√©ponse IA
      const aiResponse = await generateAIResponseFast(
        context,
        true, // isFirstMessage
        (finalText) => {
          // Callback quand le texte final est pr√™t
          console.log('‚úÖ Texte IA final re√ßu:', finalText);
          setAiThinking(false);
          setPartialAIText('');
          aiResponseCompleteRef.current = true;
          // D√©clencher le traitement de la file d'attente pour s'assurer que tous les audios sont jou√©s
          processAudioQueue();
        },
        (partialText) => {
          // Callback pour le texte partiel (feedback visuel)
          setPartialAIText(partialText);
          setAiThinking(false); // D√©sactiver "L'IA r√©fl√©chit" d√®s le premier texte
        },
        onSentenceReadyForAudio
      );

      // CRITIQUE: Ajouter √† l'historique ET √† la ref
      const newHistory = [{ role: 'assistant' as const, content: aiResponse.message }];
      setConversationContext(prev => ({ ...prev, conversationHistory: newHistory }));
      conversationHistoryRef.current = newHistory;

    } catch (error) {
      setAiThinking(false);
      setError('Erreur de connexion avec l\'IA.');
      
      // Fallback ultime
      if (!isMuted) {
        phoneCallService.setAISpeaking(true);
        const { playTextImmediately } = await import('../services/openai');
        playTextImmediately("All√¥ ?").then(() => {
            phoneCallService.setAISpeaking(false);
            setIsAISpeaking(false);
          }).catch(() => {
            phoneCallService.setAISpeaking(false);
            setIsAISpeaking(false);
          });
      } else {
        phoneCallService.setAISpeaking(false);
        setIsAISpeaking(false);
      }
    }
  };

  const handleUserSpeech = async (transcript: string) => {
    // UTILISER LES REFS pour les v√©rifications d'√©tat
    if (callStateRef.current !== 'connected') {
      return;
    }

    if (processingResponseRef.current) {
      return;
    }

    // CRITIQUE: Ajouter la transcription √† l'historique ET √† la ref
    const userMessage = { role: 'user' as const, content: transcript };
    const updatedHistory = [...conversationHistoryRef.current, userMessage];
    
    setConversationContext(prev => ({
      ...prev,
      conversationHistory: updatedHistory
    }));
    conversationHistoryRef.current = updatedHistory;
    
    // ULTRA-OPTIMISATION: R√©ponse IA imm√©diate
    setTimeout(() => {
      handleAIResponse();
    }, 10); // ULTRA-R√âDUCTION: 15ms ‚Üí 10ms pour r√©activit√© maximale
  };

  const handleAIResponse = async () => {
    if (callStateRef.current !== 'connected') {
      return;
    }

    if (processingResponseRef.current) {
      return;
    }

    processingResponseRef.current = true;
    setError(null);
    setIsAISpeaking(true);
    phoneCallService.setAISpeaking(true); // CRITIQUE: Informer le service imm√©diatement
    setAiThinking(true);
    setPartialAIText('');
    
    // R√©initialiser la file d'attente audio
    audioQueueRef.current = [];
    isAudioPlayingRef.current = false;
    aiResponseCompleteRef.current = false;
    shouldEndCallAfterAudioRef.current = false;

    try {
      // CRITIQUE: Utiliser l'historique de la ref (le plus √† jour)
      const contextForAI: ConversationContext = {
        target: config.target,
        difficulty: config.difficulty,
        conversationHistory: conversationHistoryRef.current
      };
      
      // G√©n√©rer la r√©ponse IA
      const aiResponse = await generateAIResponseFast(
        contextForAI,
        false,
        (finalText) => {
          // Callback quand le texte final est pr√™t
          console.log('‚úÖ Texte IA final re√ßu:', finalText);
          setAiThinking(false);
          setPartialAIText('');
          aiResponseCompleteRef.current = true;
          // D√©clencher le traitement de la file d'attente pour s'assurer que tous les audios sont jou√©s
          processAudioQueue();
        },
        (partialText) => {
          // Callback pour le texte partiel (feedback visuel)
          setPartialAIText(partialText);
          setAiThinking(false); // D√©sactiver "L'IA r√©fl√©chit" d√®s le premier texte
        },
        onSentenceReadyForAudio
      );
      

      // CRITIQUE: Ajouter la r√©ponse IA √† l'historique ET √† la ref
      const aiMessage = { role: 'assistant' as const, content: aiResponse.message };
      const updatedHistory = [...conversationHistoryRef.current, aiMessage];
      
      setConversationContext(prev => ({
        ...prev,
        conversationHistory: updatedHistory
      }));
      conversationHistoryRef.current = updatedHistory;
      
      setPartialAIText('');
      processingResponseRef.current = false;

      // Terminer l'appel si demand√© par l'IA
      if (aiResponse.shouldEndCall) {
        shouldEndCallAfterAudioRef.current = true;
      }

    } catch (error) {
      console.error('‚ùå Erreur handleAIResponse:', error);
      setPartialAIText('');
      setError('Erreur de connexion avec l\'IA.');
      
      // Fallback avec synth√®se vocale
      const fallbackMessage = "Pardon ?";
      if (!isMuted) {
        const { playTextImmediately } = await import('../services/openai');
        playTextImmediately(fallbackMessage).then(() => {
          phoneCallService.setAISpeaking(false);
          setIsAISpeaking(false);
        }).catch(() => {
          phoneCallService.setAISpeaking(false);
          setIsAISpeaking(false);
        });
      } else {
        setIsAISpeaking(false);
        phoneCallService.setAISpeaking(false);
      }
      
      // Ajouter le message de fallback √† l'historique
      const fallbackAIMessage = { role: 'assistant' as const, content: fallbackMessage };
      const updatedHistory = [...conversationHistoryRef.current, fallbackAIMessage];
      
      setConversationContext(prev => ({
        ...prev,
        conversationHistory: updatedHistory
      }));
      conversationHistoryRef.current = updatedHistory;
    } finally {
      // CRITIQUE : Toujours remettre les √©tats √† false
      processingResponseRef.current = false;
      setAiThinking(false);
    }
  };

  const handleEndCall = async () => {
    const callEndTime = new Date();
    setEndTime(callEndTime);
    setCallState('ended');
    callStateRef.current = 'ended';
    
    // Nettoyer la file d'attente audio
    audioQueueRef.current = [];
    isAudioPlayingRef.current = false;
    aiResponseCompleteRef.current = false;
    shouldEndCallAfterAudioRef.current = false;
    
    phoneCallService.stopRecording();
    phoneCallService.setAISpeaking(false);
    setIsAISpeaking(false);

    // Calculer la dur√©e finale pr√©cise
    const finalDuration = startTime ? Math.floor((callEndTime.getTime() - startTime.getTime()) / 1000) : callDuration;
    setCallDuration(finalDuration);

    // Arr√™ter tout audio en cours
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current = null;
    }
    window.speechSynthesis.cancel();

    // Analyser l'appel avec l'IA STRICTE
    try {
      const analysis = await analyzeCall(
        conversationHistoryRef.current, // Utiliser la ref pour l'historique le plus r√©cent
        config.target,
        config.difficulty,
        callDuration
      );

      const result: SessionResult = {
        score: analysis.score,
        feedback: analysis.strengths,
        recommendations: analysis.recommendations,
        duration: finalDuration,
        detailedAnalysis: analysis.detailedFeedback,
        improvements: analysis.improvements
      };

      onCallComplete(result);
    } catch (error) {
      // Analyse de fallback STRICTE
      const userMessages = conversationHistoryRef.current.filter(m => m.role === 'user');
      const totalWords = userMessages.reduce((total, msg) => total + msg.content.split(' ').length, 0);
      
      // SCORING STRICT pour fallback
      let fallbackScore = 0;
      if (userMessages.length === 0) fallbackScore = 0;
      else if (userMessages.length === 1 && totalWords < 10) fallbackScore = 15;
      else if (totalWords < 25) fallbackScore = 35;
      else fallbackScore = Math.min(60, 25 + userMessages.length * 5);

      const fallbackResult: SessionResult = {
        score: fallbackScore,
        feedback: fallbackScore > 30 ? [
          'Tu as particip√© √† la conversation',
          'Effort de communication visible'
        ] : [],
        recommendations: [
          'Pr√©pare une accroche de 30 secondes',
          'Structure ton discours commercial',
          'Entra√Æne-toi quotidiennement'
        ],
        duration: finalDuration,
        detailedAnalysis: `Performance ${fallbackScore < 30 ? 'tr√®s insuffisante' : fallbackScore < 50 ? 'insuffisante' : 'correcte'}. ${fallbackScore < 30 ? 'Il faut au minimum te pr√©senter et expliquer l\'objet de l\'appel.' : 'Continue √† t\'entra√Æner pour am√©liorer ta technique commerciale.'}`,
        improvements: fallbackScore < 40 ? [
          'Conversation trop courte',
          'Manque de structure commerciale',
          'Pas assez d\'engagement'
        ] : [
          'Gestion des objections',
          'Techniques de questionnement',
          'Closing commercial'
        ]
      };

      onCallComplete(fallbackResult);
    }
  };

  const formatTime = (seconds: number) => {
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = seconds % 60;
    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
  };

  const getContactInfo = () => {
    const contactMap = {
      secretary: { 
        name: 'Marie Dubois', 
        title: 'Secr√©taire', 
        company: 'Entreprise ABC',
        avatar: 'üë©‚Äçüíº',
        color: 'from-blue-500 to-blue-600' 
      },
      hr: { 
        name: 'Pierre Martin', 
        title: 'Directeur RH', 
        company: 'Groupe XYZ',
        avatar: 'üë®‚Äçüíº',
        color: 'from-purple-500 to-purple-600' 
      },
      manager: { 
        name: 'Sophie Laurent', 
        title: 'Directrice', 
        company: 'Innovation Corp',
        avatar: 'üë©‚Äçüíº',
        color: 'from-primary-500 to-primary-600' 
      },
      sales: { 
        name: 'Thomas Durand', 
        title: 'Commercial', 
        company: 'Vente Pro',
        avatar: 'üë®‚Äçüíº',
        color: 'from-accent-500 to-accent-600' 
      }
    };
    return contactMap[config.target as keyof typeof contactMap] || contactMap.secretary;
  };

  const contact = getContactInfo();

  const getCallStateText = () => {
    switch (callState) {
      case 'dialing': return 'Composition...';
      case 'ringing': return 'Sonnerie...';
      case 'connected': return 'En cours';
      case 'ended': return 'Termin√©';
    }
  };

  const getCallStateColor = () => {
    switch (callState) {
      case 'dialing': return 'text-yellow-400';
      case 'ringing': return 'text-blue-400';
      case 'connected': return 'text-green-400';
      case 'ended': return 'text-red-400';
    }
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-gray-900 via-gray-800 to-black flex items-center justify-center p-4">
      <div className="w-full max-w-sm mx-auto">
        {/* Interface d'appel t√©l√©phonique */}
        <div className="bg-gray-900 rounded-3xl shadow-2xl border border-gray-700 overflow-hidden">
          {/* Header */}
          <div className="bg-gradient-to-r from-gray-800 to-gray-700 px-6 py-4 text-center">
            <div className={`text-sm font-medium ${getCallStateColor()}`}>
              {getCallStateText()}
            </div>
            <div className="text-white text-lg font-semibold mt-1">
              {formatTime(callDuration)}
            </div>
          </div>

          {/* Contact Info */}
          <div className="px-8 py-12 text-center">
            <div className="mb-6">
              <div className={`w-32 h-32 mx-auto rounded-full bg-gradient-to-br ${contact.color} flex items-center justify-center text-6xl shadow-2xl transition-all duration-300`}>
                {contact.avatar}
              </div>
            </div>
            
            <h2 className="text-2xl font-bold text-white mb-2">
              {contact.name}
            </h2>
            <p className="text-gray-300 text-lg mb-1">
              {contact.title}
            </p>
            <p className="text-gray-400">
              {contact.company}
            </p>

            {/* Status indicators */}
            <div className="mt-8 space-y-3">
              {callState === 'ringing' && (
                <div className="flex items-center justify-center space-x-2 text-blue-400">
                  <div className="w-2 h-2 bg-blue-400 rounded-full animate-bounce"></div>
                  <div className="w-2 h-2 bg-blue-400 rounded-full animate-bounce" style={{ animationDelay: '0.1s' }}></div>
                  <div className="w-2 h-2 bg-blue-400 rounded-full animate-bounce" style={{ animationDelay: '0.2s' }}></div>
                </div>
              )}

              {aiThinking && callState === 'connected' && (
                <div className="bg-blue-900/50 border border-blue-500 rounded-lg p-3">
                  <div className="flex items-center justify-center space-x-2 text-blue-300">
                    <div className="w-2 h-2 bg-blue-400 rounded-full animate-bounce"></div>
                    <div className="w-2 h-2 bg-blue-400 rounded-full animate-bounce" style={{ animationDelay: '0.1s' }}></div>
                    <div className="w-2 h-2 bg-blue-400 rounded-full animate-bounce" style={{ animationDelay: '0.2s' }}></div>
                    <span className="ml-2 text-sm">L'IA r√©fl√©chit...</span>
                  </div>
                </div>
              )}

            </div>
          </div>

          {/* Controls */}
          <div className="px-8 pb-8">
            <div className="flex justify-center space-x-6">
              {callState === 'connected' && (
                <button
                  onClick={() => setIsMuted(!isMuted)}
                  className={`p-4 rounded-full transition-all duration-300 ${
                    isMuted 
                      ? 'bg-red-500 hover:bg-red-600' 
                      : 'bg-gray-700 hover:bg-gray-600'
                  }`}
                >
                  {isMuted ? (
                    <VolumeX className="h-6 w-6 text-white" />
                  ) : (
                    <Volume2 className="h-6 w-6 text-white" />
                  )}
                </button>
              )}

              <button
                onClick={handleEndCall}
                disabled={callState === 'ended'}
                className="bg-red-500 hover:bg-red-600 disabled:bg-gray-600 p-4 rounded-full transition-all duration-300 hover:scale-110 disabled:scale-100"
              >
                <PhoneOff className="h-8 w-8 text-white" />
              </button>
            </div>

            <div className="text-center mt-6">
              <p className="text-gray-400 text-sm">
                {aiThinking ? 'L\'IA g√©n√®re sa r√©ponse...' : 'Parlez naturellement, l\'IA vous √©coute'}
              </p>
            </div>
          </div>
        </div>

        {/* Instructions */}
        {callState === 'dialing' && (
          <div className="mt-6 text-center">
            <p className="text-gray-400 text-sm">
              Pr√©paration de l'appel en cours...
            </p>
          </div>
        )}
      </div>
    </div>
  );
}

export default PhoneCallSimulator;