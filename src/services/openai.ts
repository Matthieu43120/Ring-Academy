// Configuration de l'API OpenAI
// Derni√®re mise √† jour: correction du param√®tre isFirstMessage
const OPENAI_PROXY_URL = '/.netlify/functions/openai-proxy';
// Version: 1.2.1 - Optimisations de performance et stabilit√©
const OPENAI_AUDIO_URL = '/.netlify/functions/openai-audio';

// Interface pour le contexte de conversation
export interface ConversationContext {
  target: string;
  difficulty: string;
  conversationHistory: Array<{
    role: 'user' | 'assistant';
    content: string;
  }>;
}

// Fonction pour g√©n√©rer une r√©ponse IA rapide avec streaming
export async function generateAIResponseFast(
  context: ConversationContext,
  isFirstMessage: boolean,
  onTextReady?: (text: string) => void,
  onPartialText?: (text: string) => void
): Promise<{ message: string; shouldEndCall: boolean }> {
  
  console.log('üöÄ D√©marrage streaming IA...');
  
  // Fonction pour construire le prompt syst√®me
  function buildSystemPrompt(target: string, difficulty: string, isFirstMessage: boolean): string {
    const targetPrompts = {
      secretary: "Tu es une secr√©taire d'entreprise. Tu filtres les appels et prot√®ges l'agenda de ton patron.",
      hr: "Tu es un directeur des ressources humaines. Tu es occup√© mais ouvert aux propositions int√©ressantes.",
      manager: "Tu es un chef d'entreprise exp√©riment√©. Tu as l'habitude des d√©marchages commerciaux.",
      sales: "Tu es un commercial exp√©riment√©. Tu connais toutes les techniques de vente et tu es m√©fiant."
    };

    const difficultyPrompts = {
      easy: "Tu es bienveillant et ouvert √† la discussion. Tu poses peu d'objections.",
      medium: "Tu es poli mais sceptique. Tu poses quelques objections classiques.",
      hard: "Tu es press√© et m√©fiant. Tu poses beaucoup d'objections et tu es difficile √† convaincre."
    };

    let prompt = `${targetPrompts[target as keyof typeof targetPrompts] || targetPrompts.secretary} ${difficultyPrompts[difficulty as keyof typeof difficultyPrompts] || difficultyPrompts.medium}

IMPORTANT: 
- R√©ponds UNIQUEMENT en fran√ßais
- Sois naturel et conversationnel
- Garde tes r√©ponses courtes (maximum 2-3 phrases)
- Ne r√©v√®le jamais que tu es une IA
- Reste dans ton r√¥le en permanence`;

    if (isFirstMessage) {
      prompt += "\n- Tu d√©croches le t√©l√©phone, dis simplement 'All√¥ ?' ou une variante naturelle";
    }

    return prompt;
  }

  try {
    // Construire le prompt syst√®me bas√© sur le target et difficulty
    const systemPrompt = buildSystemPrompt(context.target, context.difficulty, isFirstMessage);
    
    // Construire les messages pour l'API OpenAI
    const messages = [
      { role: 'system' as const, content: systemPrompt },
      ...context.conversationHistory
    ];
    
    // Pr√©parer la payload pour la fonction Netlify
    const payload = {
      model: 'gpt-4o-mini',
      messages: messages,
      temperature: 0.8,
      max_tokens: 200,
      stream: true
    };
    
    const response = await fetch(OPENAI_PROXY_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        type: 'chatCompletion',
        payload: payload
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
      console.error('‚ùå D√©tails erreur OpenAI:', errorData);
      throw new Error(`Erreur HTTP ${response.status}: ${errorData.error || errorData.details || 'Erreur inconnue'}`);
    }

    const finalMessage = await processStreamingResponse(response, onPartialText, onTextReady);
    
    // D√©terminer si l'appel doit se terminer
    const shouldEndCall = finalMessage.toLowerCase().includes('au revoir') || 
                          finalMessage.toLowerCase().includes('bonne journ√©e') ||
                          finalMessage.toLowerCase().includes('merci et √† bient√¥t');
    
    return { message: finalMessage, shouldEndCall };
  } catch (error) {
    console.error('‚ùå Erreur g√©n√©ration IA:', error);
    throw error;
  }
}

// Fonction pour traiter la r√©ponse streaming
async function processStreamingResponse(
  response: Response,
  onPartialText?: (text: string) => void,
  onTextReady?: (text: string) => void
): Promise<string> {
  const reader = response.body?.getReader();
  if (!reader) {
    throw new Error('Impossible de lire la r√©ponse streaming');
  }

  const decoder = new TextDecoder();
  let accumulatedText = '';
  let hasStartedProcessing = false;

  try {
    while (true) {
      const { done, value } = await reader.read();
      
      if (done) {
        console.log('‚úÖ Streaming termin√©');
        break;
      }

      const chunk = decoder.decode(value, { stream: true });

      // Traiter chaque ligne du chunk
      const lines = chunk.split('\n');
      
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = line.slice(6);
          
          if (data === '[DONE]') {
            console.log('üèÅ Signal de fin re√ßu');
            break;
          }

          try {
            const parsed = JSON.parse(data);
            const content = parsed.choices?.[0]?.delta?.content || '';
            
            if (content) {
              if (!hasStartedProcessing) {
                hasStartedProcessing = true;
                console.log('üéØ Premier contenu re√ßu, d√©marrage traitement...');
              }

              accumulatedText += content;

              // Callback pour le texte partiel
              if (onPartialText) {
                onPartialText(accumulatedText);
              }
            }
          } catch (parseError) {
            console.warn('‚ö†Ô∏è Erreur parsing JSON:', parseError);
          }
        }
      }
    }


    const cleanMessage = accumulatedText.trim();
    console.log('‚úÖ Message IA final:', cleanMessage);
    
    // Callback final avec le texte complet
    if (onTextReady && cleanMessage) {
      onTextReady(cleanMessage);
    }

    return cleanMessage;
  } finally {
    reader.releaseLock();
  }
}

// Fonction pour g√©n√©rer l'AudioBuffer d'une phrase (sans la jouer)
export async function getAudioBufferForSentence(text: string): Promise<AudioBuffer> {
  console.log('üéµ G√©n√©ration AudioBuffer pour:', text.substring(0, 30) + '...');
  
  try {
    const response = await fetch(OPENAI_AUDIO_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        type: 'speech',
        payload: {
          input: text,
          voice: 'nova',
          model: 'tts-1'
        }
      }),
    });

    if (!response.ok) {
      throw new Error(`Erreur g√©n√©ration audio: ${response.status}`);
    }

    const result = await response.json();
    
    if (!result.audioBase64) {
      throw new Error('Pas de donn√©es audio re√ßues');
    }

    // D√©coder le Base64 en ArrayBuffer
    const audioData = Uint8Array.from(atob(result.audioBase64), c => c.charCodeAt(0));
    
    // Cr√©er un AudioContext pour d√©coder
    const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
    
    // D√©coder l'audio en AudioBuffer
    const audioBuffer = await audioContext.decodeAudioData(audioData.buffer);
    
    console.log('‚úÖ AudioBuffer g√©n√©r√© avec succ√®s');
    return audioBuffer;
    
  } catch (error) {
    console.error('‚ùå Erreur g√©n√©ration AudioBuffer:', error);
    throw error;
  }
}

// Fonction pour jouer un AudioBuffer
export async function playAudioBuffer(audioBuffer: AudioBuffer): Promise<void> {
  return new Promise((resolve, reject) => {
    try {
      console.log('üîä D√©but lecture AudioBuffer');
      
      // Cr√©er un AudioContext pour la lecture
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      
      // Cr√©er une source audio
      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.destination);
      
      // G√©rer la fin de lecture
      source.onended = () => {
        console.log('üîä Lecture AudioBuffer termin√©e');
        resolve();
      };
      
      // D√©marrer la lecture
      source.start(0);
      
    } catch (error) {
      console.error('‚ùå Erreur lecture AudioBuffer:', error);
      reject(error);
    }
  });
}


// Fonction pour g√©n√©rer et jouer un segment audio (conserv√©e pour compatibilit√©)
export async function generateAndPlaySegmentAudio(text: string): Promise<void> {
  try {
    console.log('üéµ G√©n√©ration et lecture pour:', text.substring(0, 30) + '...');
    const audioBuffer = await getAudioBufferForSentence(text);
    await playAudioBuffer(audioBuffer);
  } catch (error) {
    console.error('‚ùå Erreur g√©n√©ration/lecture segment:', error);
    // Fallback vers la synth√®se vocale du navigateur
    await playTextImmediately(text);
  }
}

// Fonction fallback pour jouer le texte imm√©diatement avec la synth√®se vocale
export async function playTextImmediately(text: string): Promise<void> {
  return new Promise((resolve) => {
    if ('speechSynthesis' in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'fr-FR';
      utterance.rate = 1.1;
      utterance.pitch = 1.0;
      
      utterance.onend = () => {
        console.log('üîä Synth√®se vocale termin√©e');
        resolve();
      };
      
      utterance.onerror = () => {
        console.warn('‚ö†Ô∏è Erreur synth√®se vocale');
        resolve();
      };
      
      speechSynthesis.speak(utterance);
      console.log('üîä D√©but synth√®se vocale');
    } else {
      console.warn('‚ö†Ô∏è Synth√®se vocale non support√©e');
      resolve();
    }
  });
}

// Fonction pour transcrire l'audio (utilis√©e par phoneCallService)
export async function transcribeAudio(audioBlob: Blob): Promise<string> {
  try {
    const formData = new FormData();
    formData.append('audio', audioBlob, 'audio.webm');

    const response = await fetch(OPENAI_AUDIO_URL, {
      method: 'POST',
      body: formData,
    });

    if (!response.ok) {
      throw new Error(`Erreur transcription: ${response.status}`);
    }

    const result = await response.json();
    return result.text || '';
  } catch (error) {
    console.error('‚ùå Erreur transcription:', error);
    return '';
  }
}

// Fonction pour analyser un appel et g√©n√©rer un rapport
export async function analyzeCall(
  conversationHistory: Array<{ role: string; content: string }>,
  target: string,
  difficulty: string,
  duration: number
): Promise<{
  score: number;
  strengths: string[];
  recommendations: string[];
  detailedFeedback: string;
  improvements: string[];
}> {
  try {
    console.log('üîç Analyse de l\'appel en cours...');
    
    // Pr√©parer les messages pour l'analyse
    const analysisMessages = [
      {
        role: 'system' as const,
        content: `Tu es un expert en prospection t√©l√©phonique. Analyse cette conversation et fournis un rapport d√©taill√©.
        
        Crit√®res d'√©valuation :
        - Qualit√© de l'approche et de l'accroche
        - Gestion des objections
        - Capacit√© d'√©coute et d'adaptation
        - Clart√© du discours
        - Atteinte de l'objectif (prise de rendez-vous)
        
        Fournis une r√©ponse JSON avec :
        - score (sur 100)
        - strengths (array de points forts)
        - recommendations (array de recommandations)
        - detailedFeedback (analyse d√©taill√©e)
        - improvements (array d'axes d'am√©lioration)`
      },
      {
        role: 'user' as const,
        content: `Analyse cette conversation de prospection :
        
        Cible : ${target}
        Difficult√© : ${difficulty}
        Dur√©e : ${Math.round(duration / 1000)}s
        
        Conversation :
        ${conversationHistory.map(msg => `${msg.role}: ${msg.content}`).join('\n')}`
      }
    ];

    // Pr√©parer la payload pour la fonction Netlify
    const payload = {
      model: 'gpt-4o-mini',
      messages: analysisMessages,
      temperature: 0.3,
      max_tokens: 1000
    };
    
    const response = await fetch(OPENAI_PROXY_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        type: 'chatCompletion',
        payload: payload
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
      console.error('‚ùå D√©tails erreur analyse:', errorData);
      throw new Error(`Erreur HTTP ${response.status}: ${errorData.error || errorData.details || 'Erreur inconnue'}`);
    }

    const result = await response.json();
    const analysisText = result.choices?.[0]?.message?.content || '';
    
    // Nettoyer la r√©ponse pour supprimer les marqueurs Markdown
    let cleanedAnalysisText = analysisText.trim();
    
    // Supprimer les blocs de code Markdown (```json ... ```)
    if (cleanedAnalysisText.startsWith('```json')) {
      cleanedAnalysisText = cleanedAnalysisText.replace(/^```json\s*/, '');
    }
    if (cleanedAnalysisText.startsWith('```')) {
      cleanedAnalysisText = cleanedAnalysisText.replace(/^```\s*/, '');
    }
    if (cleanedAnalysisText.endsWith('```')) {
      cleanedAnalysisText = cleanedAnalysisText.replace(/\s*```$/, '');
    }
    
    console.log('üìù Texte d\'analyse nettoy√©:', cleanedAnalysisText.substring(0, 200) + '...');
    
    // Parser la r√©ponse JSON
    try {
      const analysis = JSON.parse(cleanedAnalysisText);
      console.log('‚úÖ Analyse termin√©e:', analysis);
      return analysis;
    } catch (parseError) {
      console.warn('‚ö†Ô∏è Erreur parsing analyse, utilisation fallback:', parseError);
      console.warn('üìù Texte probl√©matique:', cleanedAnalysisText);
      // Fallback si le parsing JSON √©choue
      return {
        score: 75,
        strengths: ['Bonne approche g√©n√©rale'],
        recommendations: ['Continuer √† pratiquer'],
        detailedFeedback: cleanedAnalysisText || 'Analyse non disponible',
        improvements: ['Am√©liorer la gestion des objections']
      };
    }
  } catch (error) {
    console.error('‚ùå Erreur analyse appel:', error);
    // Retourner une analyse par d√©faut en cas d'erreur
    return {
      score: 50,
      strengths: ['Participation √† la simulation'],
      recommendations: ['R√©essayer la simulation', 'Pratiquer davantage'],
      detailedFeedback: 'Une erreur est survenue lors de l\'analyse. Veuillez r√©essayer.',
      improvements: ['Am√©liorer la technique de prospection']
    };
  }
}