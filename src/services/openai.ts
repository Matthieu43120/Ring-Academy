// Configuration de l'API OpenAI
const OPENAI_PROXY_URL = '/.netlify/functions/openai-proxy';
const OPENAI_AUDIO_URL = '/.netlify/functions/openai-audio';

// Interface pour le contexte de conversation
export interface ConversationContext {
  target: string;
  difficulty: string;
  conversationHistory: Array<{
    role: 'user' | 'assistant';
    content: string;
  }>;
}

// Fonction pour g√©n√©rer une r√©ponse IA rapide avec streaming
export async function generateAIResponseFast(
  context: ConversationContext,
  isFirstMessage: boolean = false,
  onTextReady?: (text: string) => void,
  onPartialText?: (text: string) => void,
  onSentenceReadyForAudio?: (sentence: string) => void
): Promise<{ message: string; shouldEndCall: boolean }> {
  
  console.log('üöÄ D√©marrage streaming IA...');
  
  try {
    // Construire le prompt syst√®me bas√© sur le target et difficulty
    const systemPrompt = buildSystemPrompt(context.target, context.difficulty, isFirstMessage);
    
    // Construire les messages pour l'API OpenAI
    const messages = [
      { role: 'system' as const, content: systemPrompt },
      ...context.conversationHistory
    ];
    
    // Pr√©parer la payload pour la fonction Netlify
    const payload = {
      model: 'gpt-4-turbo',
      messages: messages,
      temperature: 0.8,
      max_tokens: 200,
      stream: true
    };
    
    const response = await fetch(OPENAI_PROXY_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        type: 'chatCompletion',
        payload: payload
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
      console.error('‚ùå D√©tails erreur OpenAI:', errorData);
      throw new Error(`Erreur HTTP ${response.status}: ${errorData.error || errorData.details || 'Erreur inconnue'}`);
    }

    const finalMessage = await processStreamingResponse(response, onPartialText, onSentenceReadyForAudio, onTextReady);
    
    // D√©terminer si l'appel doit se terminer
    const shouldEndCall = finalMessage.toLowerCase().includes('au revoir') || 
                          finalMessage.toLowerCase().includes('bonne journ√©e') ||
                          finalMessage.toLowerCase().includes('merci et √† bient√¥t');
    
    return { message: finalMessage, shouldEndCall };
  } catch (error) {
    console.error('‚ùå Erreur g√©n√©ration IA:', error);
    throw error;
  }
}

// Fonction pour construire le prompt syst√®me
function buildSystemPrompt(target: string, difficulty: string, isFirstMessage: boolean): string {
  const targetPrompts = {
    secretary: "Tu es une secr√©taire d'entreprise. Tu filtres les appels et prot√®ges l'agenda de ton patron.",
    hr: "Tu es un directeur des ressources humaines. Tu es occup√© mais ouvert aux propositions int√©ressantes.",
    manager: "Tu es un chef d'entreprise exp√©riment√©. Tu as l'habitude des d√©marchages commerciaux.",
    sales: "Tu es un commercial exp√©riment√©. Tu connais toutes les techniques de vente et tu es m√©fiant."
  };

  const difficultyPrompts = {
    easy: "Tu es bienveillant et ouvert √† la discussion. Tu poses peu d'objections.",
    medium: "Tu es poli mais sceptique. Tu poses quelques objections classiques.",
    hard: "Tu es press√© et m√©fiant. Tu poses beaucoup d'objections et tu es difficile √† convaincre."
  };

  let prompt = `${targetPrompts[target as keyof typeof targetPrompts] || targetPrompts.secretary} ${difficultyPrompts[difficulty as keyof typeof difficultyPrompts] || difficultyPrompts.medium}

IMPORTANT: 
- R√©ponds UNIQUEMENT en fran√ßais
- Sois naturel et conversationnel
- Garde tes r√©ponses courtes (maximum 2-3 phrases)
- Ne r√©v√®le jamais que tu es une IA
- Reste dans ton r√¥le en permanence`;

  if (isFirstMessage) {
    prompt += "\n- Tu d√©croches le t√©l√©phone, dis simplement 'All√¥ ?' ou une variante naturelle";
  }

  return prompt;
}

// Fonction pour traiter la r√©ponse streaming
async function processStreamingResponse(
  response: Response,
  onPartialText?: (text: string) => void,
  onSentenceReadyForAudio?: (sentence: string) => void,
  onTextReady?: (text: string) => void
): Promise<string> {
  const reader = response.body?.getReader();
  if (!reader) {
    throw new Error('Impossible de lire la r√©ponse streaming');
  }

  const decoder = new TextDecoder();
  let accumulatedText = '';
  let sentenceBuffer = '';
  let hasStartedProcessing = false;

  try {
    while (true) {
      const { done, value } = await reader.read();
      
      if (done) {
        console.log('‚úÖ Streaming termin√©');
        break;
      }

      const chunk = decoder.decode(value, { stream: true });
      console.log('üì¶ Chunk re√ßu:', chunk);

      // Traiter chaque ligne du chunk
      const lines = chunk.split('\n');
      
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = line.slice(6);
          
          if (data === '[DONE]') {
            console.log('üèÅ Signal de fin re√ßu');
            break;
          }

          try {
            const parsed = JSON.parse(data);
            const content = parsed.choices?.[0]?.delta?.content || '';
            
            if (content) {
              if (!hasStartedProcessing) {
                hasStartedProcessing = true;
                console.log('üéØ Premier contenu re√ßu, d√©marrage traitement...');
              }

              accumulatedText += content;
              sentenceBuffer += content;

              // Callback pour le texte partiel
              if (onPartialText) {
                onPartialText(accumulatedText);
              }

              // D√©tecter les phrases compl√®tes
              const completeSentences = extractCompleteSentences(sentenceBuffer);
              
              for (const sentence of completeSentences) {
                console.log('üéµ Phrase compl√®te d√©tect√©e:', sentence);
                
                if (onSentenceReadyForAudio) {
                  onSentenceReadyForAudio(sentence);
                }
                
                // Retirer la phrase du buffer
                sentenceBuffer = sentenceBuffer.replace(sentence, '').trim();
              }
            }
          } catch (parseError) {
            console.warn('‚ö†Ô∏è Erreur parsing JSON:', parseError);
          }
        }
      }
    }

    // Traiter le reste du buffer s'il y en a
    if (sentenceBuffer.trim()) {
      console.log('üéµ Phrase finale du buffer:', sentenceBuffer);
      if (onSentenceReadyForAudio) {
        onSentenceReadyForAudio(sentenceBuffer.trim());
      }
    }

    const cleanMessage = accumulatedText.trim();
    console.log('‚úÖ Message IA final:', cleanMessage);
    
    // Callback final avec le texte complet
    if (onTextReady && cleanMessage) {
      onTextReady(cleanMessage);
    }

    return cleanMessage;
  } finally {
    reader.releaseLock();
  }
}

// Fonction pour extraire les phrases compl√®tes
function extractCompleteSentences(text: string): string[] {
  const sentences: string[] = [];
  
  // Regex pour d√©tecter les fins de phrases
  const sentenceEndRegex = /[.!?]+\s+/g;
  let lastIndex = 0;
  let match;

  while ((match = sentenceEndRegex.exec(text)) !== null) {
    const sentence = text.slice(lastIndex, match.index + match[0].length).trim();
    if (sentence.length > 5) {
      sentences.push(sentence);
      lastIndex = match.index + match[0].length;
    }
  }

  return sentences;
}

// Fonction pour streamer et jouer l'audio OpenAI en temps r√©el
export async function streamOpenAIAudio(text: string): Promise<void> {
  console.log('üéµ Streaming audio temps r√©el pour:', text.substring(0, 50) + '...');
  
  try {
    const response = await fetch(OPENAI_AUDIO_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        type: 'speech',
        payload: {
          input: text,
          voice: 'nova',
          model: 'tts-1'
        }
      }),
    });

    if (!response.ok) {
      throw new Error(`Erreur g√©n√©ration audio: ${response.status}`);
    }

    if (!response.body) {
      throw new Error('Pas de flux audio re√ßu');
    }

    console.log('üîä D√©but streaming audio temps r√©el');
    
    // Cr√©er un AudioContext pour la lecture en temps r√©el
    const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
    
    // Utiliser l'API MediaSource pour le streaming audio
    await playStreamingAudio(response.body, audioContext);
    
  } catch (error) {
    console.error('‚ùå Erreur streaming audio:', error);
    throw error;
  }
}

// Fonction pour jouer un flux audio en temps r√©el
async function playStreamingAudio(stream: ReadableStream<Uint8Array>, audioContext: AudioContext): Promise<void> {
  return new Promise(async (resolve, reject) => {
    try {
      const reader = stream.getReader();
      const chunks: Uint8Array[] = [];
      let totalLength = 0;
      let isPlaying = false;
      
      // Lire le flux par chunks
      const readChunk = async () => {
        try {
          const { done, value } = await reader.read();
          
          if (done) {
            console.log('üîä Fin du flux audio');
            // Jouer les derniers chunks s'il en reste
            if (chunks.length > 0 && !isPlaying) {
              await playAccumulatedChunks();
            }
            resolve();
            return;
          }
          
          if (value) {
            chunks.push(value);
            totalLength += value.length;
            
            // Commencer la lecture d√®s qu'on a assez de donn√©es (environ 8KB)
            if (!isPlaying && totalLength > 8192) {
              isPlaying = true;
              await playAccumulatedChunks();
            }
          }
          
          // Continuer √† lire
          readChunk();
        } catch (error) {
          console.error('‚ùå Erreur lecture chunk:', error);
          reject(error);
        }
      };
      
      // Fonction pour jouer les chunks accumul√©s
      const playAccumulatedChunks = async () => {
        if (chunks.length === 0) return;
        
        try {
          // Combiner tous les chunks en un seul ArrayBuffer
          const combinedBuffer = new ArrayBuffer(totalLength);
          const combinedView = new Uint8Array(combinedBuffer);
          let offset = 0;
          
          for (const chunk of chunks) {
            combinedView.set(chunk, offset);
            offset += chunk.length;
          }
          
          // D√©coder et jouer l'audio
          const audioBuffer = await audioContext.decodeAudioData(combinedBuffer);
          const source = audioContext.createBufferSource();
          source.buffer = audioBuffer;
          source.connect(audioContext.destination);
          
          source.onended = () => {
            console.log('üîä Lecture chunk termin√©e');
          };
          
          source.start(0);
          console.log('üîä Lecture chunk d√©marr√©e');
          
          // R√©initialiser pour le prochain batch
          chunks.length = 0;
          totalLength = 0;
          isPlaying = false;
          
        } catch (error) {
          console.error('‚ùå Erreur lecture chunk audio:', error);
          // Continuer malgr√© l'erreur
          chunks.length = 0;
          totalLength = 0;
          isPlaying = false;
        }
      };
      
      // D√©marrer la lecture du flux
      readChunk();
      
    } catch (error) {
      console.error('‚ùå Erreur setup streaming audio:', error);
      reject(error);
    }
  });
}

// Fonction pour g√©n√©rer et jouer un segment audio
export async function generateAndPlaySegmentAudio(text: string): Promise<void> {
  try {
    console.log('üéµ G√©n√©ration et lecture pour:', text.substring(0, 30) + '...');
    await streamOpenAIAudio(text);
  } catch (error) {
    console.error('‚ùå Erreur g√©n√©ration/lecture segment:', error);
    // Fallback vers la synth√®se vocale du navigateur
    await playTextImmediately(text);
  }
}

// Fonction fallback pour jouer le texte imm√©diatement avec la synth√®se vocale
export async function playTextImmediately(text: string): Promise<void> {
  return new Promise((resolve) => {
    if ('speechSynthesis' in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'fr-FR';
      utterance.rate = 1.1;
      utterance.pitch = 1.0;
      
      utterance.onend = () => {
        console.log('üîä Synth√®se vocale termin√©e');
        resolve();
      };
      
      utterance.onerror = () => {
        console.warn('‚ö†Ô∏è Erreur synth√®se vocale');
        resolve();
      };
      
      speechSynthesis.speak(utterance);
      console.log('üîä D√©but synth√®se vocale');
    } else {
      console.warn('‚ö†Ô∏è Synth√®se vocale non support√©e');
      resolve();
    }
  });
}

// Fonction pour transcrire l'audio (utilis√©e par phoneCallService)
export async function transcribeAudio(audioBlob: Blob): Promise<string> {
  try {
    const formData = new FormData();
    formData.append('audio', audioBlob, 'audio.webm');

    const response = await fetch(OPENAI_AUDIO_URL, {
      method: 'POST',
      body: formData,
    });

    if (!response.ok) {
      throw new Error(`Erreur transcription: ${response.status}`);
    }

    const result = await response.json();
    return result.text || '';
  } catch (error) {
    console.error('‚ùå Erreur transcription:', error);
    return '';
  }
}

// Fonction pour analyser un appel et g√©n√©rer un rapport
export async function analyzeCall(
  conversationHistory: Array<{ role: string; content: string }>,
  target: string,
  difficulty: string,
  duration: number
): Promise<{
  score: number;
  strengths: string[];
  recommendations: string[];
  detailedFeedback: string;
  improvements: string[];
}> {
  try {
    console.log('üîç Analyse de l\'appel en cours...');
    
    // Pr√©parer les messages pour l'analyse
    const analysisMessages = [
      {
        role: 'system' as const,
        content: `Tu es un expert en prospection t√©l√©phonique. Analyse cette conversation et fournis un rapport d√©taill√©.
        
        Crit√®res d'√©valuation :
        - Qualit√© de l'approche et de l'accroche
        - Gestion des objections
        - Capacit√© d'√©coute et d'adaptation
        - Clart√© du discours
        - Atteinte de l'objectif (prise de rendez-vous)
        
        Fournis une r√©ponse JSON avec :
        - score (sur 100)
        - strengths (array de points forts)
        - recommendations (array de recommandations)
        - detailedFeedback (analyse d√©taill√©e)
        - improvements (array d'axes d'am√©lioration)`
      },
      {
        role: 'user' as const,
        content: `Analyse cette conversation de prospection :
        
        Cible : ${target}
        Difficult√© : ${difficulty}
        Dur√©e : ${Math.round(duration / 1000)}s
        
        Conversation :
        ${conversationHistory.map(msg => `${msg.role}: ${msg.content}`).join('\n')}`
      }
    ];

    // Pr√©parer la payload pour la fonction Netlify
    const payload = {
      model: 'gpt-4-turbo',
      messages: analysisMessages,
      temperature: 0.3,
      max_tokens: 1000
    };
    
    const response = await fetch(OPENAI_PROXY_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        type: 'chatCompletion',
        payload: payload
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
      console.error('‚ùå D√©tails erreur analyse:', errorData);
      throw new Error(`Erreur HTTP ${response.status}: ${errorData.error || errorData.details || 'Erreur inconnue'}`);
    }

    const result = await response.json();
    const analysisText = result.choices?.[0]?.message?.content || '';
    
    // Parser la r√©ponse JSON
    try {
      const analysis = JSON.parse(analysisText);
      console.log('‚úÖ Analyse termin√©e:', analysis);
      return analysis;
    } catch (parseError) {
      console.warn('‚ö†Ô∏è Erreur parsing analyse, utilisation fallback');
      // Fallback si le parsing JSON √©choue
      return {
        score: 75,
        strengths: ['Bonne approche g√©n√©rale'],
        recommendations: ['Continuer √† pratiquer'],
        detailedFeedback: analysisText || 'Analyse non disponible',
        improvements: ['Am√©liorer la gestion des objections']
      };
    }
  } catch (error) {
    console.error('‚ùå Erreur analyse appel:', error);
    // Retourner une analyse par d√©faut en cas d'erreur
    return {
      score: 50,
      strengths: ['Participation √† la simulation'],
      recommendations: ['R√©essayer la simulation', 'Pratiquer davantage'],
      detailedFeedback: 'Une erreur est survenue lors de l\'analyse. Veuillez r√©essayer.',
      improvements: ['Am√©liorer la technique de prospection']
    };
  }
}